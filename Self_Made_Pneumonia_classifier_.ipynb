{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZRSiDYNQLSr"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqesD_seVVt7",
        "outputId": "e98e8761-f7e0-4755-ee9f-eb4d544f9c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOckP_sYQcda"
      },
      "source": [
        "keras = tf.keras ## instantiate keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F9FfyFSQl_5"
      },
      "source": [
        "base_path = os.path.join(\"/content/drive/MyDrive\") ##base path for the datasets (in colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xalsFDNyQp66"
      },
      "source": [
        "train_data = np.load(os.path.join(base_path, \"traindata.npy\")) ##loading data form presaved pre-processed image\n",
        "train_label = np.load(os.path.join(base_path, \"trainlabel.npy\"))\n",
        "test_data = np.load(os.path.join(base_path, \"testdata.npy\"))\n",
        "test_label = np.load(os.path.join(base_path, \"testlabel.npy\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XryjXIYhQ_gM"
      },
      "source": [
        "train_label = keras.utils.to_categorical(train_label) ##change label to categorical to fit the model\n",
        "test_label = keras.utils.to_categorical(test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beJ_3jq4JkDD"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, validation_data, train_label, validation_label = train_test_split(train_data, train_label, test_size = 0.1) ##create validation split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_label))\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_data, validation_label)) ##create tensor dataset"
      ],
      "metadata": {
        "id": "dXUaaCXjWHY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "epochs = 10\n",
        "shuffle_buffer = 1000\n",
        "train_dataset = train_dataset.shuffle(shuffle_buffer).batch(batch_size)\n",
        "validation_dataset = validation_dataset.shuffle(shuffle_buffer).batch(batch_size) ##shuffle, and batch them datasets"
      ],
      "metadata": {
        "id": "oeIiDAqEW32m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers = tf.keras.layers\n",
        "input_shape = (256,256,3)"
      ],
      "metadata": {
        "id": "pvr1UVkMXblO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = layers.Conv2D(filters=64, kernel_size=(5,5), strides=(4,4), padding=\"valid\", activation='relu', input_shape=input_shape)\n",
        "input_pooling = layers.MaxPool2D(pool_size=(5,5), strides=(2,2))\n",
        "hidden_layer1 = layers.Conv2D(filters = 128, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\")\n",
        "hidden_layer1_pooling = layers.MaxPool2D(pool_size = (5,5), strides =(2,2))\n",
        "hidden_layer2 = layers.Conv2D(filters = 256, kernel_size = (3,3), strides=(1,1), activation='relu', padding=\"same\")\n",
        "hidden_layer2_pooling = layers.MaxPool2D(pool_size= (3,3), strides=(1,1))\n",
        "hidden_layer3 = layers.Conv2D(filters = 256, kernel_size = (3,3), strides = (1,1), activation ='relu', padding=\"valid\")\n",
        "hidden_layer3_pooling = layers.MaxPool2D(pool_size=(3,3), strides=(2,2))\n",
        "flatten_layer = layers.Flatten()\n",
        "dense_layer = layers.Dense(4096, activation = 'relu')\n",
        "dropout_layer1 = layers.Dropout(0.3)\n",
        "output_layer = layers.Dense(2, activation = 'softmax')"
      ],
      "metadata": {
        "id": "RotT3agRY8e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    input_layer,\n",
        "    layers.BatchNormalization(),\n",
        "    input_pooling,\n",
        "    hidden_layer1,\n",
        "    layers.BatchNormalization(),\n",
        "    hidden_layer1_pooling,\n",
        "    hidden_layer2,\n",
        "    layers.BatchNormalization(),\n",
        "    hidden_layer2_pooling,\n",
        "    hidden_layer3,\n",
        "    layers.BatchNormalization(),\n",
        "    hidden_layer3_pooling,\n",
        "    flatten_layer,\n",
        "    dense_layer,\n",
        "    dropout_layer1,\n",
        "    output_layer\n",
        "])"
      ],
      "metadata": {
        "id": "Zze6E4r2kp2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.optimizers.SGD(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "BhiGHH4wlfVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "root_logdir = os.path.join(os.curdir, \"logs\\\\fit\\\\\")\n",
        "def get_run_logdir():\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "run_logdir = get_run_logdir()\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
      ],
      "metadata": {
        "id": "eZ6-YzFimrup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset, callbacks=[tensorboard_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhjGV4oGmIrP",
        "outputId": "a43be03e-3a30-4225-af2a-7bcc66d47541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "67/67 [==============================] - 171s 2s/step - loss: 0.3170 - accuracy: 0.8809 - val_loss: 0.5833 - val_accuracy: 0.7290\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 142s 2s/step - loss: 0.1681 - accuracy: 0.9351 - val_loss: 0.6484 - val_accuracy: 0.7290\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 137s 2s/step - loss: 0.1179 - accuracy: 0.9568 - val_loss: 0.8295 - val_accuracy: 0.7290\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 136s 2s/step - loss: 0.0981 - accuracy: 0.9601 - val_loss: 1.2546 - val_accuracy: 0.7290\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 138s 2s/step - loss: 0.0782 - accuracy: 0.9696 - val_loss: 1.4279 - val_accuracy: 0.7290\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 142s 2s/step - loss: 0.0653 - accuracy: 0.9764 - val_loss: 1.8185 - val_accuracy: 0.7290\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 140s 2s/step - loss: 0.0577 - accuracy: 0.9780 - val_loss: 1.1534 - val_accuracy: 0.7290\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 136s 2s/step - loss: 0.0443 - accuracy: 0.9843 - val_loss: 1.3890 - val_accuracy: 0.7290\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 138s 2s/step - loss: 0.0389 - accuracy: 0.9860 - val_loss: 0.7033 - val_accuracy: 0.7941\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 138s 2s/step - loss: 0.0331 - accuracy: 0.9900 - val_loss: 0.9867 - val_accuracy: 0.7689\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff015c2d710>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_label))\n",
        "test_batches = test_dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "cjV0WKpDvUUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = model.predict(test_batches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGTcihO-v3yE",
        "outputId": "38457234-5560-4f3e-a38b-3fd105b5db64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 8s 623ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"Self_constructed_pneumonia_prediction.h5\")"
      ],
      "metadata": {
        "id": "dnPRVCB_v5Af"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}